{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('training-data-bitstrings-1725968884597180500.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Unpack the data\n",
    "X, y = data\n",
    "\n",
    "# Convert y to a DataFrame for easier handling\n",
    "df_y = pd.DataFrame(y, columns=['num_included', 'num_excluded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataset(X, max_filters=None):\n",
    "    # Function to convert bytes to binary string\n",
    "    def bytes_to_binary(byte_string):\n",
    "        return ''.join(format(byte, '08b') for byte in byte_string)\n",
    "    \n",
    "    # Convert all filters to binary strings\n",
    "    X_binary = [[bytes_to_binary(filter_bytes) for filter_bytes in sample] for sample in X]\n",
    "    \n",
    "    # Determine the maximum number of filters if not provided\n",
    "    if max_filters is None:\n",
    "        max_filters = max(len(sample) for sample in X_binary)\n",
    "    \n",
    "    # Determine the maximum length for each filter position\n",
    "    max_lengths = [max(len(sample[i]) for sample in X_binary if i < len(sample)) \n",
    "                   for i in range(max_filters)]\n",
    "    \n",
    "    # Pad each sample to have max_filters, and each filter to have the max length for its position\n",
    "    X_standardized = []\n",
    "    for sample in X_binary:\n",
    "        padded_sample = []\n",
    "        for i in range(max_filters):\n",
    "            if i < len(sample):\n",
    "                # Pad existing filter to max length\n",
    "                padded_filter = sample[i].ljust(max_lengths[i], '0')\n",
    "            else:\n",
    "                # Create empty filter of max length\n",
    "                padded_filter = '0' * max_lengths[i]\n",
    "            padded_sample.append(padded_filter)\n",
    "        X_standardized.append(padded_sample)\n",
    "    \n",
    "    # Convert to numpy array for easier handling in deep learning models\n",
    "    X_standardized = np.array(X_standardized)\n",
    "    \n",
    "    return X_standardized, max_filters, max_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of filters: 4\n",
      "Max lengths of filters: [12848, 632, 192, 96]\n",
      "Shape of standardized dataset: (10000, 4)\n",
      "\n",
      "Sample 1:\n",
      "  Filter 1: 12848 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000110000110001100000001000010100100000...\n",
      "  Filter 2: 632 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000001101101110110000000001000010010001...\n",
      "  Filter 3: 192 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000000001100100110101100001001011010000...\n",
      "  Filter 4: 96 bits\n",
      "    First 100 bits: 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000...\n",
      "\n",
      "Sample 2:\n",
      "  Filter 1: 12848 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000101010000110100101101111000110010000...\n",
      "  Filter 2: 632 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000100101000111000111010100000010100100...\n",
      "  Filter 3: 192 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000100101100010011000000100000010100000...\n",
      "  Filter 4: 96 bits\n",
      "    First 100 bits: 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000...\n",
      "\n",
      "Sample 3:\n",
      "  Filter 1: 12848 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000000011000100110011010110010010001111...\n",
      "  Filter 2: 632 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000110100100111100110001000101100111010...\n",
      "  Filter 3: 192 bits\n",
      "    First 100 bits: 0000011100000000000000000000000000000000000000000000000000000000110000100001010000000110001101110000...\n",
      "  Filter 4: 96 bits\n",
      "    First 100 bits: 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000...\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "X_standardized, max_filters, max_lengths = standardize_dataset(X)\n",
    "\n",
    "print(f\"Max number of filters: {max_filters}\")\n",
    "print(f\"Max lengths of filters: {max_lengths}\")\n",
    "print(f\"Shape of standardized dataset: {X_standardized.shape}\")\n",
    "\n",
    "# Display a few samples to verify\n",
    "for i in range(min(3, len(X_standardized))):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    for j, filter_str in enumerate(X_standardized[i]):\n",
    "        print(f\"  Filter {j+1}: {len(filter_str)} bits\")\n",
    "        print(f\"    First 100 bits: {filter_str[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_target: (10000,)\n",
      "Data type of y_target: float32\n",
      "First few values of y_target: [976. 131. 110. 851. 731.]\n"
     ]
    }
   ],
   "source": [
    "# Extract 'num_included' and convert to numpy array\n",
    "y_target = df_y['num_included'].values\n",
    "\n",
    "# Convert to float type (usually preferred for deep learning models)\n",
    "y_target = y_target.astype(np.float32)\n",
    "\n",
    "print(\"Shape of y_target:\", y_target.shape)\n",
    "print(\"Data type of y_target:\", y_target.dtype)\n",
    "print(\"First few values of y_target:\", y_target[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
